{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Thank you for using the Modin Experimental pandas API.\n",
      "Please note that some of these APIs deviate from pandas in order to provide improved performance.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import ray\n",
    "import modin.experimental.pandas as md\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from sspipe import p, px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up modin to utilize all cpu cores when tokenizing (since pandas library only uses one core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MODIN_ENGINE'] = 'ray'\n",
    "ray.init(num_cpus=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('database.db')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the data that will be tokinized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>850381</th>\n",
       "      <td>KB-lnnyWsusCPTQ0KhYoaQ</td>\n",
       "      <td>50NigUjcwHSHRDsiT69vhA</td>\n",
       "      <td>2019-04-23 23:05:33</td>\n",
       "      <td>4</td>\n",
       "      <td>Sakura is always tasty!  They do have a great ...</td>\n",
       "      <td>Sakura Japanese Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912614</th>\n",
       "      <td>uM0ljy6pQIegLJtBUw9dOQ</td>\n",
       "      <td>qq1OvFlWvzHLBsjrDk470g</td>\n",
       "      <td>2014-01-26 01:28:57</td>\n",
       "      <td>4</td>\n",
       "      <td>Ever wonder what the world would look like if ...</td>\n",
       "      <td>Steel Wheels Pizzeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859344</th>\n",
       "      <td>EvjOPotlf9pXRXzVvN4GaA</td>\n",
       "      <td>OQBudWxPFK5v9vELTOGefg</td>\n",
       "      <td>2010-12-13 08:31:35</td>\n",
       "      <td>2</td>\n",
       "      <td>acceptable food, bad order accuracy, they seem...</td>\n",
       "      <td>Caesar's Bistro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916408</th>\n",
       "      <td>khH0QtNyUjcExh9i2CwGfg</td>\n",
       "      <td>gskrVpxfBFOc8PLnnuKAkA</td>\n",
       "      <td>2015-02-17 00:13:17</td>\n",
       "      <td>5</td>\n",
       "      <td>This place will be number one on the best of p...</td>\n",
       "      <td>Serpico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707063</th>\n",
       "      <td>MzFhaFNbE03zF84BPkN7yQ</td>\n",
       "      <td>YP9ciaV5YPGXIKNIs2y7Kg</td>\n",
       "      <td>2011-12-22 17:40:34</td>\n",
       "      <td>4</td>\n",
       "      <td>I've been here a couple of times and have been...</td>\n",
       "      <td>Sang Kee Noodle House</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    business_id               review_id                 date  \\\n",
       "850381   KB-lnnyWsusCPTQ0KhYoaQ  50NigUjcwHSHRDsiT69vhA  2019-04-23 23:05:33   \n",
       "2912614  uM0ljy6pQIegLJtBUw9dOQ  qq1OvFlWvzHLBsjrDk470g  2014-01-26 01:28:57   \n",
       "1859344  EvjOPotlf9pXRXzVvN4GaA  OQBudWxPFK5v9vELTOGefg  2010-12-13 08:31:35   \n",
       "1916408  khH0QtNyUjcExh9i2CwGfg  gskrVpxfBFOc8PLnnuKAkA  2015-02-17 00:13:17   \n",
       "1707063  MzFhaFNbE03zF84BPkN7yQ  YP9ciaV5YPGXIKNIs2y7Kg  2011-12-22 17:40:34   \n",
       "\n",
       "         stars                                               text  \\\n",
       "850381       4  Sakura is always tasty!  They do have a great ...   \n",
       "2912614      4  Ever wonder what the world would look like if ...   \n",
       "1859344      2  acceptable food, bad order accuracy, they seem...   \n",
       "1916408      5  This place will be number one on the best of p...   \n",
       "1707063      4  I've been here a couple of times and have been...   \n",
       "\n",
       "                               name  \n",
       "850381   Sakura Japanese Restaurant  \n",
       "2912614       Steel Wheels Pizzeria  \n",
       "1859344             Caesar's Bistro  \n",
       "1916408                     Serpico  \n",
       "1707063       Sang Kee Noodle House  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = md.read_sql('SELECT `business_id`, `review_id`, `date`, `stars`, `text`, `name` FROM resturants_review', db)\n",
    "review.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenCleaner():\n",
    "    def __init__(self, remove_stopwords=True, return_as_string=True):\n",
    "\n",
    "        # Some punctuation variations\n",
    "        self.punctuation = set(punctuation)  # speeds up comparison\n",
    "        self.punct_set = self.punctuation - {\"#\"}\n",
    "        self.punct_pattern = \\\n",
    "            re.compile(\"[\" + re.escape(\"\".join(self.punct_set)) + \"]\")\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.ZERO_WIDTH_JOINER = '\\u200d'\n",
    "\n",
    "        # Stopwords\n",
    "        if remove_stopwords:\n",
    "            self.sw = stopwords.words(\"english\") + ['️', '', ' ']\n",
    "        else:\n",
    "            self.sw = ''\n",
    "\n",
    "        # Two useful regex\n",
    "        self.whitespace_pattern = re.compile(r\"\\s+\")\n",
    "        self.hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "        self.CleanText_return_format = return_as_string\n",
    "\n",
    "    def CleanText(self, _text):\n",
    "        # if _text is has nothing in it then return none\n",
    "        if _text is None:\n",
    "            return ''\n",
    "\n",
    "        # decode bytes to string if necessary\n",
    "        if isinstance(_text, str):\n",
    "            self.text = _text\n",
    "        elif isinstance(_text, float):\n",
    "            self.text = str(_text)\n",
    "        else:\n",
    "            # this is for the case of tweets which are saved as bytes\n",
    "            self.text = _text.decode(\"utf-8\")\n",
    "\n",
    "        self.__add_space_before_and_after_emoji()\n",
    "        self.__RemovePunctuation()\n",
    "        self.__TokenizeText()\n",
    "        self.__StemEachToken()\n",
    "        self.__RemoveStopWords()\n",
    "\n",
    "        if self.CleanText_return_format:\n",
    "            return ' '.join(self.tokens)\n",
    "        else:\n",
    "            return self.tokens\n",
    "\n",
    "    def __StemEachToken(self):\n",
    "        \"\"\"\n",
    "        Perform Stemming on each token (i.e. working, worked, works are all converted to work)<\n",
    "        \"\"\"\n",
    "\n",
    "        self.tokens = [self.stemmer.stem(token) for token in self.tokens]\n",
    "\n",
    "    def __add_space_before_and_after_emoji(self):\n",
    "        text_section = list()\n",
    "        for i, char in enumerate(self.text):\n",
    "            if emoji.is_emoji(char):\n",
    "                text_section.append(' ' + self.text[i] + ' ')\n",
    "            else:\n",
    "                text_section.append(self.text[i])\n",
    "\n",
    "            if self.ZERO_WIDTH_JOINER in text_section:\n",
    "                text_section.remove(self.ZERO_WIDTH_JOINER)\n",
    "\n",
    "        return ''.join(text_section)\n",
    "\n",
    "    def __RemovePunctuation(self):\n",
    "        \"\"\"\n",
    "        Loop through the original text and check each character,\n",
    "        if the character is a punctuation, then it is removed.\n",
    "        ---------------------------------------------------------\n",
    "        input: original text\n",
    "        output: text without punctuation\n",
    "        \"\"\"\n",
    "        self.text = \\\n",
    "            \"\".join([ch for ch in self.text if ch not in self.punct_set])\n",
    "\n",
    "        self.text = re.sub(self.punct_pattern, '', self.text)\n",
    "\n",
    "    def __TokenizeText(self):\n",
    "        \"\"\"\n",
    "        Tokenize by splitting the text by white space\n",
    "        ---------------------------------------------------------\n",
    "        input: text without punctuation\n",
    "        output: A list of tokens\n",
    "        \"\"\"\n",
    "        self.tokens = \\\n",
    "            [item for item in self.whitespace_pattern.split(self.text)]\n",
    "\n",
    "    def __RemoveStopWords(self):\n",
    "        \"\"\"\n",
    "        Tokenize by splitting the text by white space\n",
    "        ---------------------------------------------------------\n",
    "        input: text without punctuation\n",
    "        output: A list of tokens with all token as lower case\n",
    "        \"\"\"\n",
    "        self.tokens = [token.lower() for token in self.tokens]\n",
    "\n",
    "        self.tokens = \\\n",
    "            [token for token in self.tokens if not token in self.sw]\n",
    "\n",
    "\n",
    "def add_space_after_emoji(text):\n",
    "\n",
    "    text_section = list()\n",
    "    for i, char in enumerate(text):\n",
    "        if emoji.is_emoji(char):\n",
    "            text_section.append(' ' + text[i] + ' ')\n",
    "        else:\n",
    "            text_section.append(text[i])\n",
    "\n",
    "        if self.ZERO_WIDTH_JOINER in text_section:\n",
    "            text_section.remove(self.ZERO_WIDTH_JOINER)\n",
    "\n",
    "    return ''.join(text_section)\n",
    "\n",
    "\n",
    "def clean_string(text):\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "\n",
    "    remove_words = stopwords.words(\"english\") + ['️', '', ' ']\n",
    "    text = text.replace('|', ' ').replace('\\n', ' ')\n",
    "\n",
    "    text = re.sub(punct_pattern, '', text)\n",
    "    text = add_space_after_emoji(text)\n",
    "    text_tokens = text.split(' ')\n",
    "    text = [word.lower() for word in text_tokens]\n",
    "    text = [word for word in text if not word in remove_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TokenCleaner()\n",
    "\n",
    "review['tokenized'] = review['text'].apply(tc.CleanText)\n",
    "review.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review._to_pandas().to_sql('resturants_review', db, if_exists='replace', index=False)\n",
    "db.commit()\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9fc20e1815138d30c667ffde1bd8baef1681fb1fc5d82ed7f911b8c6ab1ce59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
